{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0293c111297a61481508202fcd690d673b0775ece2d2d867b62b8842b676a9a30",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Boltzmann Machine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\\n!unzip ml-1m.zip\\n!ls\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "##Downloading the dataset\n",
    "\n",
    "###ML-100K\n",
    "'''\n",
    "!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "!unzip ml-100k.zip\n",
    "!ls\n",
    "'''\n",
    "###ML-1M\n",
    "'''\n",
    "!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
    "!unzip ml-1m.zip\n",
    "!ls\n",
    "'''"
   ]
  },
  {
   "source": [
    "## Importing the libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "source": [
    "## Importing the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "source": [
    "## Preparing the training set and the test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [user, movie, rating, time_stamp]\n",
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "source": [
    "## Getting the number of users and movies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"
   ]
  },
  {
   "source": [
    "## Converting the data into an array with users in lines and movies in columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat list of list with each user with column all the movies with ratings\n",
    "# [ [1, 2, 0, 1 ....], .....] rating if the movie rated by the user or zero\n",
    "# |  |              |\n",
    "# |  Movie_1, ......|\n",
    "# [User_1___________], .....]\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        # movie ids rated by id_user\n",
    "        # [data[:,0] == id_users] : get rows only with user == id_users \n",
    "        id_movies = data[:, 1] [data[:, 0] == id_users]\n",
    "        id_ratings = data[:, 2] [data[:, 0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        # id_movies start with index One\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "source": [
    "## Converting the data into Torch tensors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "source": [
    "## Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 0 -> -1 : 0 means movie is not rated by the user\n",
    "\n",
    "training_set[training_set == 0] = -1\n",
    "# 0 for low ratings (1 or 2 stars)\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "# 1 for higher ratings (3,4,5 stars)\n",
    "training_set[training_set >= 3] = 1\n",
    "\n",
    "test_set[test_set == 0] = -1\n",
    "# 0 for low ratings (1 or 2 stars)\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "# 1 for higher ratings (3,4,5 stars)\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "source": [
    "## Creating the architecture of the Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "\n",
    "    def __init__(self, nv, nh ):# nv and nh : number of visible and hidden nodes.\n",
    "        self.W = torch.randn(nh, nv) # init weights(size nh by nv) random with normal distribution\n",
    "        # Bias for probabilities of hidden nodes given the visible nodes, dimensions batch and bias\n",
    "        self.a = torch.randn(1, nh)\n",
    "        #                    |   |_Bias\n",
    "        #                    Batch\n",
    "        # Bias for probabilities of visible nodes given the hidden nodes, dimensions batch and bias\n",
    "        self.b = torch.randn(1, nv)\n",
    "\n",
    "    def sample_h(self, x):# sampling the hidden node according to probabilities of hidden nodes given visible nodes. (sigmoid activation function), x : values of visible nodes, 'v' in the probabilities of hidden nodes (ph) given visible nodes (v).\n",
    "        # compute the probability of h given v (probability that hidden neuron equals one given the values of visible neurons)\n",
    "        wx = torch.mm(x, self.W.t()) # product w, x, t() : get transpose\n",
    "        activation = wx + self.a.expand_as(wx) # expand_as(wx) : make sure to add bias to each line of minibatchs\n",
    "        p_h_given_v = torch.sigmoid(activation)# apply the sigmoid function to activations\n",
    "        # torch.bernoulli(p_h_given_v) : bernoulli sampling\n",
    "        # Draws binary random numbers (0 or 1) from a Bernoulli distribution\n",
    "        # if i'th visible node with probability = 0.25, then get random number between 0 and 1 if the random number < 0.25 then the i'th visible node get value 1 else 0\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y): # y : values of hidden nodes\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    # k-step contractat divergence\n",
    "    # v0 : input vector\n",
    "    # vk : visible node after k samplings \n",
    "    # ph0 : vector of probabilities at the first iteration, hidden node equal one with given values of v0\n",
    "    # phk : probabilities of the hidden node after k samplings given the values of visible node vk\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "source": [
    "## Training the RBM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch : 1 loss : 0.3405577838420868\n",
      "epoch : 2 loss : 0.23860925436019897\n",
      "epoch : 3 loss : 0.253926157951355\n",
      "epoch : 4 loss : 0.24895991384983063\n",
      "epoch : 5 loss : 0.24922935664653778\n",
      "epoch : 6 loss : 0.24672900140285492\n",
      "epoch : 7 loss : 0.24650555849075317\n",
      "epoch : 8 loss : 0.24651718139648438\n",
      "epoch : 9 loss : 0.2483144849538803\n",
      "epoch : 10 loss : 0.24779851734638214\n"
     ]
    }
   ],
   "source": [
    "nv = len(training_set[0]) # visible nodes\n",
    "nh = 100 # hidden nodes\n",
    "batch_size = 100\n",
    "\n",
    "rbm = RBM(nv, nh)\n",
    "\n",
    "nb_epoch = 10 # number of epochs\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0 # simple difference and absolute value (lost function)\n",
    "    s = 0.0 # counter for normalize the error\n",
    "\n",
    "    # batch\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user : id_user + batch_size]\n",
    "        v0 = training_set[id_user : id_user + batch_size] # for keep the original ratings of users \n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "\n",
    "        # k-steps of contrastive divergent (random walk) (gibbs sampling)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0] # -1 ratings (not rated by user) keep -1\n",
    "        \n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk) # update weights and bias\n",
    "        # update the train lost\n",
    "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0])) # calculate simple difference and absolute value (ignore -1 ratings)\n",
    "        # update the counter\n",
    "        s += 1.0\n",
    "    print(f\"epoch : {epoch} loss : {train_loss/s}\")"
   ]
  },
  {
   "source": [
    "## Testing the RBM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test loss: tensor(0.2444)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  }
 ]
}